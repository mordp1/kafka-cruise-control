{{- define "kafka-cruise-control-configmap" -}}
{{- $cruise_control := . -}}
---
{{ range .Values.cruise_control_list }}
{{- $container_name := printf "kafka-cruise-control_%s_%s" .config.application_name .config.environment | lower |replace "_" "-"| replace "*" "all" |replace "." "-" }}
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    team: {{ $cruise_control.Values.team }}
    env: {{ .config.environment }}
    instance_type: {{ .config.instance_type }}
  name: config-{{ $container_name }}
  namespace: {{ $cruise_control.Values.namespace }}
data:
  cruisecontrol.properties: |  
     # The Kafka cluster to control.
     bootstrap.servers={{ .config.bootstrap_servers }}
     
     # The zookeeper connect of the Kafka cluster
     zookeeper.connect={{ .config.zookeeper_connect }}
     
     # The metric sampler class
     metric.sampler.class=com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsReporterSampler

     # Use the Prometheus Metric Sampler
     #metric.sampler.class=com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.PrometheusMetricSampler
     
     # True if the sampling process allows CPU capacity estimation of brokers used for CPU utilization estimation.
     sampling.allow.cpu.capacity.estimation=true
     
     # Configurations for CruiseControlMetricsReporterSampler
     metric.reporter.topic=__CruiseControlMetrics
     
     # The sample store class name
     sample.store.class=com.linkedin.kafka.cruisecontrol.monitor.sampling.KafkaSampleStore
     
     # The config for the Kafka sample store to save the partition metric samples
     partition.metric.sample.store.topic=__KafkaCruiseControlPartitionMetricSamples
     
     # The config for the Kafka sample store to save the model training samples
     broker.metric.sample.store.topic=__KafkaCruiseControlModelTrainingSamples
     
     # The replication factor of Kafka metric sample store topic
     sample.store.topic.replication.factor=2
     
     # The config for the number of Kafka sample store consumer threads
     num.sample.loading.threads=8
     
     # The partition assignor class for the metric samplers
     metric.sampler.partition.assignor.class=com.linkedin.kafka.cruisecontrol.monitor.sampling.DefaultMetricSamplerPartitionAssignor
     
     # The metric sampling interval in milliseconds
     metric.sampling.interval.ms=120000
     
     # The partition metrics window size in milliseconds
     partition.metrics.window.ms=300000
     
     # The number of partition metric windows to keep in memory. Partition-load-history = num.partition.metrics.windows * partition.metrics.window.ms
     num.partition.metrics.windows=5
     
     # The minimum partition metric samples required for a partition in each window
     min.samples.per.partition.metrics.window=1
     
     # The broker metrics window size in milliseconds
     broker.metrics.window.ms=300000
     
     # The number of broker metric windows to keep in memory. Broker-load-history = num.broker.metrics.windows * broker.metrics.window.ms
     num.broker.metrics.windows=20
     
     # The minimum broker metric samples required for a partition in each window
     min.samples.per.broker.metrics.window=1
     
     # The configuration for the BrokerCapacityConfigFileResolver (supports JBOD, non-JBOD, and heterogeneous CPU core capacities)
     capacity.config.file=capacity/capacity.json
     #capacity.config.file=config/capacityJBOD.json
     
     # Configurations for the analyzer
     # =======================================
     
     # The list of goals to optimize the Kafka cluster for with pre-computed proposals -- consider using RackAwareDistributionGoal instead of RackAwareGoal in clusters with partitions whose replication factor > number of racks. The value must be a subset of the "goals" and a superset of the "hard.goals" and "self.healing.goals".
     default.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.PotentialNwOutGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.TopicReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.LeaderReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.LeaderBytesInDistributionGoal
     
     # The list of supported goals
     goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.BrokerSetAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.PotentialNwOutGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.TopicReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.LeaderReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.LeaderBytesInDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.kafkaassigner.KafkaAssignerDiskUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.kafkaassigner.KafkaAssignerEvenRackAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.PreferredLeaderElectionGoal
     
     # The list of supported intra-broker goals
     intra.broker.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.IntraBrokerDiskCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.IntraBrokerDiskUsageDistributionGoal
     
     # The list of supported hard goals -- consider using RackAwareDistributionGoal instead of RackAwareGoal in clusters with partitions whose replication factor > number of racks
     hard.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuCapacityGoal
     
     # The minimum percentage of well monitored partitions out of all the partitions
     min.valid.partition.ratio=0.95
     
     # The balance threshold for CPU
     cpu.balance.threshold=1.1
     
     # The balance threshold for disk
     disk.balance.threshold=1.1
     
     # The balance threshold for network inbound utilization
     network.inbound.balance.threshold=1.1
     
     # The balance threshold for network outbound utilization
     network.outbound.balance.threshold=1.1
     
     # The balance threshold for the replica count
     replica.count.balance.threshold=1.1
     
     # The capacity threshold for CPU in percentage
     cpu.capacity.threshold=0.7
     
     # The capacity threshold for disk in percentage
     disk.capacity.threshold=0.8
     
     # The capacity threshold for network inbound utilization in percentage
     network.inbound.capacity.threshold=0.8
     
     # The capacity threshold for network outbound utilization in percentage
     network.outbound.capacity.threshold=0.8
     
     # The threshold to define the cluster to be in a low CPU utilization state
     cpu.low.utilization.threshold=0.0
     
     # The threshold to define the cluster to be in a low disk utilization state
     disk.low.utilization.threshold=0.0
     
     # The threshold to define the cluster to be in a low network inbound utilization state
     network.inbound.low.utilization.threshold=0.0
     
     # The threshold to define the cluster to be in a low network outbound utilization state
     network.outbound.low.utilization.threshold=0.0
     
     # The metric anomaly percentile upper threshold
     metric.anomaly.percentile.upper.threshold=90.0
     
     # The metric anomaly percentile lower threshold
     metric.anomaly.percentile.lower.threshold=10.0
     
     # How often should the cached proposal be expired and recalculated if necessary
     proposal.expiration.ms=60000
     
     # The maximum number of replicas that can reside on a broker at any given time.
     max.replicas.per.broker=10000
     
     # The number of threads to use for proposal candidate precomputing.
     num.proposal.precompute.threads=1
     
     # Configurations for the executor
     # =======================================
    
     # If true, appropriate zookeeper Client { .. } entry required in jaas file located at $base_dir/config/cruise_control_jaas.conf
     zookeeper.security.enabled=false
     
     # The max number of partitions to move in/out on a given broker at a given time.
     num.concurrent.partition.movements.per.broker=10
     
     # The upper bound of partitions to move in cluster at a given time
     max.num.cluster.partition.movements=1250
     
     # The max number of partitions to move between disks within a given broker at a given time.
     num.concurrent.intra.broker.partition.movements=2
     
     # The max number of leadership movement within the whole cluster at a given time.
     num.concurrent.leader.movements=1000
     
     # The interval between two execution progress checks.
     execution.progress.check.interval.ms=10000
     
     # Configurations for anomaly detector
     # =======================================
     
     # The goal violation notifier class
     anomaly.notifier.class=com.linkedin.kafka.cruisecontrol.detector.notifier.SelfHealingNotifier
     
     # The metric anomaly finder class
     metric.anomaly.finder.class=com.linkedin.kafka.cruisecontrol.detector.KafkaMetricAnomalyFinder
     
     # The anomaly detection interval
     #anomaly.detection.interval.ms=10000
     
     # The goal violation to detect -- consider using RackAwareDistributionGoal instead of RackAwareGoal in clusters with partitions whose replication factor > number of racks
     anomaly.detection.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuCapacityGoal
     
     # The interested metrics for metric anomaly analyzer.
     metric.anomaly.analyzer.metrics=BROKER_PRODUCE_LOCAL_TIME_MS_50TH,BROKER_PRODUCE_LOCAL_TIME_MS_999TH,BROKER_CONSUMER_FETCH_LOCAL_TIME_MS_50TH,BROKER_CONSUMER_FETCH_LOCAL_TIME_MS_999TH,BROKER_FOLLOWER_FETCH_LOCAL_TIME_MS_50TH,BROKER_FOLLOWER_FETCH_LOCAL_TIME_MS_999TH,BROKER_LOG_FLUSH_TIME_MS_50TH,BROKER_LOG_FLUSH_TIME_MS_999TH
     
     # True if recently demoted brokers are excluded from optimizations during self healing, false otherwise
     self.healing.exclude.recently.demoted.brokers=true
     
     # True if recently removed brokers are excluded from optimizations during self healing, false otherwise
     self.healing.exclude.recently.removed.brokers=true
     
     # The zk path to store failed broker information.
     failed.brokers.zk.path=/CruiseControlBrokerList
     
     # Topic config provider class
     topic.config.provider.class=com.linkedin.kafka.cruisecontrol.config.KafkaAdminTopicConfigProvider
     
     # The cluster configurations for the TopicConfigProvider
     cluster.configs.file=config/clusterConfigs.json
     
     # The maximum time in milliseconds to store the response and access details of a completed kafka monitoring user task.
     completed.kafka.monitor.user.task.retention.time.ms=86400000
     
     # The maximum time in milliseconds to store the response and access details of a completed cruise control monitoring user task.
     completed.cruise.control.monitor.user.task.retention.time.ms=86400000
     
     # The maximum time in milliseconds to store the response and access details of a completed kafka admin user task.
     completed.kafka.admin.user.task.retention.time.ms=604800000
     
     # The maximum time in milliseconds to store the response and access details of a completed cruise control admin user task.
     completed.cruise.control.admin.user.task.retention.time.ms=604800000
     
     # The fallback maximum time in milliseconds to store the response and access details of a completed user task.
     completed.user.task.retention.time.ms=86400000
     
     # The maximum time in milliseconds to retain the demotion history of brokers.
     demotion.history.retention.time.ms=1209600000
     
     # The maximum time in milliseconds to retain the removal history of brokers.
     removal.history.retention.time.ms=1209600000
     
     # The maximum number of completed kafka monitoring user tasks for which the response and access details will be cached.
     max.cached.completed.kafka.monitor.user.tasks=20
     
     # The maximum number of completed cruise control monitoring user tasks for which the response and access details will be cached.
     max.cached.completed.cruise.control.monitor.user.tasks=20
     
     # The maximum number of completed kafka admin user tasks for which the response and access details will be cached.
     max.cached.completed.kafka.admin.user.tasks=30
     
     # The maximum number of completed cruise control admin user tasks for which the response and access details will be cached.
     max.cached.completed.cruise.control.admin.user.tasks=30
     
     # The fallback maximum number of completed user tasks of certain type for which the response and access details will be cached.
     max.cached.completed.user.tasks=25
     
     # The maximum number of user tasks for concurrently running in async endpoints across all users.
     max.active.user.tasks=5
     
     # Enable self healing for all anomaly detectors, unless the particular anomaly detector is explicitly disabled
     self.healing.enabled=false
     
     # configurations for the webserver
     # ================================
     
     # HTTP listen port
     webserver.http.port=9091
     
     # HTTP listen address
     webserver.http.address=0.0.0.0
     
     # Whether CORS support is enabled for API or not
     webserver.http.cors.enabled=false
     
     # Value for Access-Control-Allow-Origin
     webserver.http.cors.origin=http://localhost:8080/
     
     # Value for Access-Control-Request-Method
     webserver.http.cors.allowmethods=OPTIONS,GET,POST
     # Admin Interface
     webserver.http.cors.exposeheaders=User-Task-ID
     
     # REST API default prefix (dont forget the ending /*)
     webserver.api.urlprefix=/kafkacruisecontrol/*
     
     # Location where the Cruise Control frontend is deployed
     webserver.ui.diskpath=./cruise-control-ui/dist/
     
     # URL path prefix for UI (dont forget the ending /*)
     webserver.ui.urlprefix=/*
     
     # Time After which request is converted to Async
     webserver.request.maxBlockTimeMs=10000
     
     # Default Session Expiry Period
     webserver.session.maxExpiryTimeMs=60000
     
     # Session cookie path
     webserver.session.path=/
     
     # Server Access Logs
     webserver.accesslog.enabled=true
     
     # Configurations for servlet
     # ==========================
     
     # Enable two-step verification for processing POST requests.
     two.step.verification.enabled=false
     
     # The maximum time in milliseconds to retain the requests in two-step (verification) purgatory.
     two.step.purgatory.retention.time.ms=1209600000
     
     # The maximum number of requests in two-step (verification) purgatory.
     two.step.purgatory.max.requests=25
     
     #Enable Vertx API with Swagger
     vertx.enabled=false
     #prometheus
     #prometheus.server.endpoint=http://prometheus:909

  capacity.json: |
    {
    "brokerCapacities": [
      {
        "brokerId": "-1",
        "capacity": {
          "DISK": "{{ int .config.capacities_disk }}",
          "CPU": {
            "num.cores": "{{ .config.capacities_num_cores }}"
          },
          "NW_IN": "{{ int .config.capacities_nw_in }}",
          "NW_OUT": "{{ int .config.capacities_nw_in }}"
        },
        "doc": "Capacity unit used for disk is in MB, cpu is in number of cores, network throughput is in KB.",
        "doc2": "instance_type={{ .config.instance_type }}"
      }
    ]
    }
---
{{- end }}
{{- end }}